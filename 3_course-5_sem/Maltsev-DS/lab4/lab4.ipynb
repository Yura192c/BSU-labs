{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузить данные согласно своему варианту. Данные представляют\n",
    "собой таблицу, состоящую из 5 столбцов: 1 столбец – это номер класса,\n",
    "к которому принадлежит наблюдение, остальные столбцы – некоторые\n",
    "переменные, которыми задано текущее наблюдение. Предполагается, что\n",
    "данные распределены по многомерному нормальному закону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv('var9.csv', delimiter=';', encoding='latin-1')\n",
    "\n",
    "print(data.head())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Удалить из выборки 15 случайных наблюдений (сохранить их\n",
    "отдельно). Оставшуюся выборку назовем обучающей. По ней мы будет\n",
    "обучать классификаторы. Сохраненные отдельно 15 наблюдений будем\n",
    "называть проверочн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Удаление 15 случайных наблюдений и сохранение их\n",
    "random_observation = data.sample(n=15, random_state=42)\n",
    "data_train = data.drop(random_observation.index)\n",
    "\n",
    "# Разделение данных на обучающую и проверочную выборки\n",
    "train_data, validation_data = train_test_split(data_train, test_size=15, random_state=42)\n",
    "\n",
    "# Вывод информации о размере обучающей и проверочной выборок\n",
    "print(\"Размер обучающей выборки:\", len(train_data))\n",
    "print(\"Размер проверочной выборки:\", len(validation_data))\n",
    "\n",
    "# Сохранение данных в отдельные файлы (если нужно)\n",
    "# random_observation.to_csv('random_observation.csv', index=False)\n",
    "# train_data.to_csv('train_data.csv', index=False)\n",
    "# validation_data.to_csv('validation_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Построить линейный классификатор для решения задачи\n",
    "классификации (см. файл Filzmoser-Lections.pdf стр. 50–51). Метод основан на\n",
    "применении модели линейной регрессии для классификации. Реализовать\n",
    "классификатор означает обучить его на имеющейся выборке (если это\n",
    "необходимо), после чего уметь классифицировать любое новое наблюдение.\n",
    "Обучить классификатор на обучающей выборке. Применить его\n",
    "к проверочной выборке. Вывести количество ошибок, которое дал\n",
    "построенный классификатор для проверочной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Разделение данных на признаки (X) и метки классов (y)\n",
    "X_train = train_data.iloc[:, 1:]\n",
    "y_train = train_data.iloc[:, 0]\n",
    "\n",
    "X_validation = validation_data.iloc[:, 1:]\n",
    "y_validation = validation_data.iloc[:, 0]\n",
    "\n",
    "# Создание и обучение модели линейной регрессии\n",
    "linear_classifier = LinearRegression()\n",
    "linear_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Применение модели к проверочной выборке\n",
    "predictions = linear_classifier.predict(X_validation)\n",
    "\n",
    "# Округление предсказанных значений до 0 или 1\n",
    "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "\n",
    "# Оценка качества классификации\n",
    "accuracy = accuracy_score(y_validation, predicted_labels)\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Количество ошибок на проверочной выборке:\", sum(y_validation != predicted_labels))\n",
    "print(f\"Accuracy на проверочной выборке: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Реализовать метод классификации k-ближайших соседей (kNN,\n",
    "k-nearest neighbors) для k = 3 и k = 5. Для нахождения расстояния использовать\n",
    "классическую Евклидову метрику. Применить его к проверочной выборке.\n",
    "Вывести количество ошибок, которое дал построенный классификатор для\n",
    "проверочной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Разделение данных на признаки (X) и метки классов (y)\n",
    "X_train = train_data.iloc[:, 1:]\n",
    "y_train = train_data.iloc[:, 0]\n",
    "\n",
    "X_validation = validation_data.iloc[:, 1:]\n",
    "y_validation = validation_data.iloc[:, 0]\n",
    "\n",
    "# Реализация k-ближайших соседей для k=3\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_3.fit(X_train, y_train)\n",
    "predictions_3 = knn_3.predict(X_validation)\n",
    "\n",
    "# Оценка качества классификации для k=3\n",
    "accuracy_3 = accuracy_score(y_validation, predictions_3)\n",
    "\n",
    "# Вывод результата для k=3\n",
    "print(\"Количество ошибок (k=3) на проверочной выборке:\", sum(y_validation != predictions_3))\n",
    "print(f\"Accuracy (k=3) на проверочной выборке: {accuracy_3*100:.2f}%\")\n",
    "\n",
    "# Реализация k-ближайших соседей для k=5\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_5.fit(X_train, y_train)\n",
    "predictions_5 = knn_5.predict(X_validation)\n",
    "\n",
    "# Оценка качества классификации для k=5\n",
    "accuracy_5 = accuracy_score(y_validation, predictions_5)\n",
    "\n",
    "# Вывод результата для k=5\n",
    "print(\"\\nКоличество ошибок (k=5) на проверочной выборке:\", sum(y_validation != predictions_5))\n",
    "print(f\"Accuracy (k=5) на проверочной выборке: {accuracy_5*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (0,5 балла) Из переменных, описывающих наблюдения, выбрать две,\n",
    "построить для них диаграмму рассеяния. Цвет и форму точек менять в\n",
    "зависимости от номера класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Выбор переменных\n",
    "variable1 = \"x.1\"\n",
    "variable2 = \"x.2\"\n",
    "\n",
    "# Выбираем два класса для построения диаграммы\n",
    "selected_classes = [1, 2]\n",
    "\n",
    "# Отбираем данные для выбранных классов\n",
    "selected_data = data[data['class'].isin(selected_classes)]\n",
    "\n",
    "# Добавление информации о классах к данным\n",
    "selected_data['Class'] = selected_data['class'].apply(lambda x: str(x))\n",
    "\n",
    "# Построение диаграммы рассеяния\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=variable1, y=variable2, hue='Class', style='Class', data=selected_data, palette='viridis', s=100,\n",
    "                )\n",
    "plt.title(f\"Scatter Plot for {variable1} vs {variable2}\")\n",
    "plt.xlabel(variable1)\n",
    "plt.ylabel(variable2)\n",
    "plt.legend(title='Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Выбор двух переменных для построения диаграммы рассеяния\n",
    "variable1 = \"x.1\"\n",
    "variable2 = \"x.2\"\n",
    "\n",
    "# Создание цветового словаря для каждого класса\n",
    "class_colors = {1: 'blue', 2 :'green'}\n",
    "\n",
    "# Создание диаграммы рассеяния\n",
    "plt.figure(figsize=(10, 6))\n",
    "for class_num, color in class_colors.items():\n",
    "    class_data = data[data['class'] == class_num]\n",
    "    plt.scatter(class_data[variable1], class_data[variable2], label=f\"Класс {class_num}\", color=color)\n",
    "\n",
    "# Настройка внешнего вида диаграммы\n",
    "plt.title(f\"Диаграмма рассеяния для {variable1} и {variable2}\")\n",
    "plt.xlabel(variable1)\n",
    "plt.ylabel(variable2)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (1 балл) Построить линейный классификатор на основе только двух\n",
    "переменных, выбранных в пункте 5. Изобразить на этой диаграмме границы\n",
    "классов, получаемые для построенного линейного классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Выбор переменных\n",
    "variable1 = \"x.1\"\n",
    "variable2 = \"x.2\"\n",
    "\n",
    "# Выбираем два класса для построения диаграммы\n",
    "selected_classes = [1, 2]\n",
    "\n",
    "# Отбираем данные для выбранных классов\n",
    "selected_data = data[data['class'].isin(selected_classes)]\n",
    "\n",
    "# Разделение данных на признаки и метки классов\n",
    "X = selected_data[[variable1, variable2]]\n",
    "y = selected_data['class']\n",
    "\n",
    "# Создание и обучение модели SVM\n",
    "svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "svm_classifier.fit(X, y)\n",
    "\n",
    "# Построение диаграммы рассеяния\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=variable1, y=variable2, hue='class', style='class', data=selected_data, palette='viridis', s=100,\n",
    "                markers=['o', 's'])\n",
    "\n",
    "# Построение границ классов\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# Создание сетки для предсказания\n",
    "xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 100), np.linspace(ylim[0], ylim[1], 100))\n",
    "Z = svm_classifier.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Отображение границы решения и границ классов\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "\n",
    "plt.title(f\"Linear SVM Classifier with Decision Boundaries ({variable1} vs {variable2})\")\n",
    "plt.xlabel(variable1)\n",
    "plt.ylabel(variable2)\n",
    "plt.legend(title='Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (0,5 балла) Изобразить границы остальных классификаторов,\n",
    "построенных на основе выбранных двух переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Создание и обучение модели логистической регрессии\n",
    "logistic_classifier = LogisticRegression()\n",
    "logistic_classifier.fit(X, y)\n",
    "\n",
    "# Создание и обучение модели k-ближайших соседей для k=3\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_3.fit(X, y)\n",
    "\n",
    "# Создание и обучение модели k-ближайших соседей для k=5\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_5.fit(X, y)\n",
    "\n",
    "# Построение границ для каждого классификатора\n",
    "classifiers = [svm_classifier, logistic_classifier, knn_3, knn_5]\n",
    "classifier_names = ['Linear SVM', 'Logistic Regression', 'k-NN (k=3)', 'k-NN (k=5)']\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i, classifier in enumerate(classifiers, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "\n",
    "    # Построение диаграммы рассеяния\n",
    "    sns.scatterplot(x=variable1, y=variable2, hue='class', style='class', data=selected_data, palette='viridis', s=100,\n",
    "                    markers=['o', 's'])\n",
    "\n",
    "    # Построение границ классов\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # Создание сетки для предсказания\n",
    "    xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 100), np.linspace(ylim[0], ylim[1], 100))\n",
    "    Z = classifier.decision_function(np.c_[xx.ravel(), yy.ravel()]) if hasattr(classifier, 'decision_function') else None\n",
    "\n",
    "    if Z is not None:\n",
    "        # Для SVM и логистической регрессии отображаем только границу решения\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "    else:\n",
    "        # Для k-NN отображаем границу классов\n",
    "        Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "\n",
    "    plt.title(f\"{classifier_names[i-1]} Decision Boundaries\")\n",
    "    plt.xlabel(variable1)\n",
    "    plt.ylabel(variable2)\n",
    "    plt.legend(title='Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (1 балл) Реализовать метод линейного дискриминантного анализа\n",
    "(см. файл Filzmoser-Lections.pdf стр. 51–53 и конспект лекций). Обучить\n",
    "классификатор на обучающей выборке. Применить его к проверочной\n",
    "выборке. Вывести количество ошибок, которое дал построенный\n",
    "классификатор для проверочной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Разделение данных на признаки и метки классов\n",
    "X_train = train_data.iloc[:, 1:]\n",
    "y_train = train_data.iloc[:, 0]\n",
    "\n",
    "X_validation = validation_data.iloc[:, 1:]\n",
    "y_validation = validation_data.iloc[:, 0]\n",
    "\n",
    "# Создание и обучение модели LDA\n",
    "lda_classifier = LinearDiscriminantAnalysis()\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Применение модели к проверочной выборке\n",
    "predictions_lda = lda_classifier.predict(X_validation)\n",
    "\n",
    "# Оценка качества классификации и вывод результата\n",
    "accuracy_lda = accuracy_score(y_validation, predictions_lda)\n",
    "error_count_lda = sum(y_validation != predictions_lda)\n",
    "\n",
    "print(\"Количество ошибок (LDA) на проверочной выборке:\", error_count_lda)\n",
    "print(\"Accuracy (LDA) на проверочной выборке:\", accuracy_lda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. (1 балл) Реализовать метод квадратичного дискриминантного анализа\n",
    "(см. файл Filzmoser-Lections.pdf стр. 53 и конспект лекций). Обучить\n",
    "классификатор на обучающей выборке. Применить его к проверочной\n",
    "выборке. Вывести количество ошибо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Разделение данных на признаки и метки классов\n",
    "X_train = train_data.iloc[:, 1:]\n",
    "y_train = train_data.iloc[:, 0]\n",
    "\n",
    "X_validation = validation_data.iloc[:, 1:]\n",
    "y_validation = validation_data.iloc[:, 0]\n",
    "\n",
    "# Создание и обучение модели QDA\n",
    "qda_classifier = QuadraticDiscriminantAnalysis()\n",
    "qda_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Применение модели к проверочной выборке\n",
    "predictions_qda = qda_classifier.predict(X_validation)\n",
    "\n",
    "# Оценка качества классификации и вывод результата\n",
    "accuracy_qda = accuracy_score(y_validation, predictions_qda)\n",
    "error_count_qda = sum(y_validation != predictions_qda)\n",
    "\n",
    "print(\"Количество ошибок (QDA) на проверочной выборке:\", error_count_qda)\n",
    "print(\"Accuracy (QDA) на проверочной выборке:\", accuracy_qda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. (1 балл) Разобраться в методе опорных векторов (svm, support vector\n",
    "machine) для 2 классов. В выборке оставить наблюдения только из 2 классов.\n",
    "Применить готовую реализацию. Проинтерпретировать полученные\n",
    "результаты. Проиллюстрировать результаты работы метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Выбор переменных\n",
    "variable1 = \"x.1\"\n",
    "variable2 = \"x.2\"\n",
    "\n",
    "# Выбираем два класса для анализа\n",
    "selected_classes = [1, 2]\n",
    "\n",
    "# Отбираем данные для выбранных классов\n",
    "selected_data_svm = data[data['class'].isin(selected_classes)]\n",
    "\n",
    "# Разделение данных на признаки и метки классов\n",
    "X_svm = selected_data_svm[[variable1, variable2]]\n",
    "y_svm = selected_data_svm['class']\n",
    "\n",
    "# Создание и обучение модели SVM\n",
    "svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "svm_classifier.fit(X_svm, y_svm)\n",
    "\n",
    "# Построение диаграммы рассеяния\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=variable1, y=variable2, hue='class', style='class', data=selected_data_svm, palette='viridis', s=100,\n",
    "                markers=['o', 's'])\n",
    "\n",
    "# Построение границы решения SVM\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# Создание сетки для предсказания\n",
    "xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 100), np.linspace(ylim[0], ylim[1], 100))\n",
    "Z = svm_classifier.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Отображение границы решения\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "\n",
    "plt.title(f\"SVM Decision Boundary ({variable1} vs {variable2})\")\n",
    "plt.xlabel(variable1)\n",
    "plt.ylabel(variable2)\n",
    "plt.legend(title='Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. (2 балла) Для всех реализованных методов классификации данных\n",
    "реализовать описанный выше метод сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Задаем долю p\n",
    "p = 0.1\n",
    "\n",
    "# Количество повторений\n",
    "M = 100\n",
    "\n",
    "# Список для сохранения вероятностей ошибок для каждого метода\n",
    "error_probabilities = []\n",
    "\n",
    "# Разделение данных на признаки и метки классов\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "# Применяем метод сравнения для каждого метода классификации\n",
    "for classifier, classifier_name in zip([svm_classifier, logistic_classifier, knn_3, knn_5, lda_classifier, qda_classifier],\n",
    "                                       ['Linear SVM', 'Logistic Regression', 'k-NN (k=3)', 'k-NN (k=5)', 'LDA', 'QDA']):\n",
    "    error_rates = []\n",
    "    for _ in range(M):\n",
    "        # Разбиваем данные на обучающую и тестовую выборки случайным образом\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=p, random_state=None)\n",
    "\n",
    "        # Обучение модели\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Предсказание на тестовой выборке\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Вычисление вероятности ошибочной классификации\n",
    "        error_rate = 1 - accuracy_score(y_test, y_pred)\n",
    "        error_rates.append(error_rate)\n",
    "\n",
    "    # Сохраняем усредненную вероятность ошибки для текущего метода\n",
    "    mean_error_rate = np.mean(error_rates)\n",
    "    error_probabilities.append((classifier_name, mean_error_rate))\n",
    "\n",
    "# Вывод результатов\n",
    "for classifier_name, mean_error_rate in error_probabilities:\n",
    "    print(f\"Средняя вероятность ошибки для {classifier_name}: {mean_error_rate*100:.4f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
